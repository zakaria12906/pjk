# üß™ GUIDE DE TEST - √âtape par √âtape

## Pr√©requis

Avant de commencer, assurez-vous d'avoir:
- Docker install√© (version ‚â• 20.10)
- Docker Compose install√© (version ‚â• 2.0)
- Au moins 8GB de RAM disponible
- Ports libres: 9870, 9000, 8080, 8081, 9092, 27017

---

## üìã √âTAPE 1 - V√©rifier les Pr√©requis

```bash
# V√©rifier Docker
docker --version
# Attendu: Docker version 20.10.x ou sup√©rieur

# V√©rifier Docker Compose
docker-compose --version
# Attendu: Docker Compose version 2.x.x ou sup√©rieur

# V√©rifier l'espace disque
df -h
# Attendu: Au moins 10GB disponible

# Aller dans le r√©pertoire du projet
cd /Users/zakariaeelouazzani/Desktop/Projet_charazad
```

**‚úÖ R√©sultat attendu**: Toutes les commandes s'ex√©cutent sans erreur

---

## üìã √âTAPE 2 - D√©marrer l'Architecture Big Data

```bash
# D√©marrer tous les services en arri√®re-plan
docker-compose up -d

# Attendre que tous les services d√©marrent (environ 2 minutes)
echo "‚è≥ Attente du d√©marrage des services (2 minutes)..."
sleep 120
```

**‚úÖ R√©sultat attendu**: 
```
Creating network "projet_charazad_default" with the default driver
Creating namenode   ... done
Creating datanode   ... done
Creating zookeeper  ... done
Creating spark-master ... done
Creating spark-worker ... done
Creating kafka      ... done
Creating mongodb    ... done
```

---

## üìã √âTAPE 3 - V√©rifier l'√âtat des Services

```bash
# Voir tous les conteneurs en cours d'ex√©cution
docker-compose ps
```

**‚úÖ R√©sultat attendu**: Tous les services affichent "Up"

```
NAME                COMMAND                  SERVICE             STATUS
datanode           "/entrypoint.sh /run‚Ä¶"   datanode            Up
kafka              "/etc/confluent/dock‚Ä¶"   kafka               Up
mongodb            "docker-entrypoint.s‚Ä¶"   mongodb             Up
namenode           "/entrypoint.sh /run‚Ä¶"   namenode            Up
spark-master       "/opt/bitnami/script‚Ä¶"   spark-master        Up
spark-worker       "/opt/bitnami/script‚Ä¶"   spark-worker        Up
zookeeper          "/etc/confluent/dock‚Ä¶"   zookeeper           Up
```

### V√©rifier les logs de chaque service

```bash
# V√©rifier HDFS NameNode
docker logs namenode | tail -20

# V√©rifier Spark Master
docker logs spark-master | tail -20

# V√©rifier Kafka
docker logs kafka | tail -20

# V√©rifier MongoDB
docker logs mongodb | tail -20
```

**‚úÖ R√©sultat attendu**: Aucun message d'erreur critique

---

## üìã √âTAPE 4 - V√©rifier les Interfaces Web

Ouvrez votre navigateur et acc√©dez aux URLs suivantes:

### 4.1 HDFS NameNode
**URL**: http://localhost:9870

**‚úÖ R√©sultat attendu**:
- Page "Overview" d'HDFS
- Section "Summary" montrant:
  - Configured Capacity: > 0 GB
  - DFS Used: quelques MB
  - Live Nodes: 1

### 4.2 Spark Master
**URL**: http://localhost:8080

**‚úÖ R√©sultat attendu**:
- Page "Spark Master"
- Section "Workers": 1 worker actif
- Status: ALIVE
- Cores: 2 ou plus
- Memory: plusieurs GB

### 4.3 Spark Worker
**URL**: http://localhost:8081

**‚úÖ R√©sultat attendu**:
- Page "Spark Worker"
- Status: ALIVE
- Master URL: spark://spark-master:7077

---

## üìã √âTAPE 5 - Pr√©parer HDFS

```bash
# Se connecter au conteneur NameNode
docker exec -it namenode bash

# Cr√©er le r√©pertoire pour les logs
hdfs dfs -mkdir -p /logs

# Donner les permissions
hdfs dfs -chmod -R 777 /logs

# Copier le fichier de logs dans HDFS
hdfs dfs -put /data/web_server.log /logs/

# V√©rifier que le fichier est pr√©sent
hdfs dfs -ls /logs

# Afficher les premi√®res lignes du fichier
hdfs dfs -cat /logs/web_server.log | head -10

# Quitter le conteneur
exit
```

**‚úÖ R√©sultat attendu**:
```
Found 1 items
-rw-r--r--   3 root supergroup      XXXX 2025-02-03 21:00 /logs/web_server.log
```

Vous devriez voir les 10 premi√®res lignes des logs affich√©es.

---

## üìã √âTAPE 6 - Test de l'Analyse BATCH (Top 10 Produits)

### 6.1 Lancer l'analyse

```bash
# Ex√©cuter l'analyse batch
docker exec spark-master spark-submit \
  --master spark://spark-master:7077 \
  --packages org.mongodb.spark:mongo-spark-connector_2.12:3.0.1 \
  /spark-apps/batch/top_products.py
```

**‚úÖ R√©sultat attendu**:
- Le job Spark d√©marre
- Affichage des logs de traitement
- Message final: "Job termin√© avec succ√®s" ou similaire
- Dur√©e: environ 30-60 secondes

**üìä Surveillez**:
- http://localhost:8080 ‚Üí Section "Running Applications"
- Vous devriez voir votre application en cours

### 6.2 V√©rifier les r√©sultats dans MongoDB

```bash
# Se connecter √† MongoDB
docker exec -it mongodb mongo

# Utiliser la base de donn√©es
use logs_analytics

# Afficher les collections
show collections

# Afficher les r√©sultats
db.top_products.find().pretty()
```

**‚úÖ R√©sultat attendu**:
```json
{
    "_id" : ObjectId("..."),
    "product_id" : "105",
    "product_category" : "lipstick",
    "request_count" : 12,
    "analysis_date" : "2025-02-03",
    "data_source" : "hdfs:///logs/web_server.log"
}
```

Vous devriez voir **10 produits** class√©s par nombre de requ√™tes (d√©croissant).

### 6.3 Compter les r√©sultats

```bash
# Dans MongoDB (toujours connect√©)
db.top_products.count()
```

**‚úÖ R√©sultat attendu**: `10` (exactement 10 produits)

```bash
# Quitter MongoDB
exit
```

---

## üìã √âTAPE 7 - Test de l'Analyse STREAMING (D√©tection d'Erreurs)

Cette √©tape n√©cessite **3 terminaux** en parall√®le.

### 7.1 Terminal 1 - D√©marrer le Producteur Kafka

```bash
# Terminal 1
cd /Users/zakariaeelouazzani/Desktop/Projet_charazad

# Se connecter au conteneur Kafka
docker exec -it kafka bash

# Aller dans le r√©pertoire des applications Kafka
cd /kafka-apps

# Installer les d√©pendances Python
pip3 install -r requirements.txt

# Lancer le producteur
python3 log_producer.py
```

**Menu du producteur**:
```
=== Simulateur de Logs Web ===
1. NORMAL - Trafic normal
2. ERRORS - Pic d'erreurs (500/404)
3. TRENDING - Produit en tendance
4. Quitter

Choix:
```

**üëâ Choisissez**: `2` (ERRORS)

**Dur√©e d'envoi en secondes**: `300` (5 minutes)

**‚úÖ R√©sultat attendu**:
```
üöÄ D√©marrage du mode ERRORS
‚è±Ô∏è  Dur√©e: 300 secondes
üìä Envoi de logs avec erreurs...

‚úÖ Log envoy√© (1/300): 192.168.x.x - 500
‚úÖ Log envoy√© (2/300): 192.168.x.x - 404
...
```

**‚ö†Ô∏è Laissez ce terminal ouvert et actif**

---

### 7.2 Terminal 2 - D√©marrer Spark Streaming

```bash
# Terminal 2
cd /Users/zakariaeelouazzani/Desktop/Projet_charazad

# Lancer l'analyse streaming
docker exec spark-master spark-submit \
  --master spark://spark-master:7077 \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0,org.mongodb.spark:mongo-spark-connector_2.12:3.0.1 \
  /spark-apps/streaming/error_detection.py
```

**‚úÖ R√©sultat attendu**:
```
Starting Spark Streaming Job...
Consuming from Kafka topic: web-logs
Window duration: 5 minutes
...
Batch: 0
-------------------------------------------
Batch: 1
-------------------------------------------
+---+-------+
|code|count |
+---+-------+
|500 |15    |
|404 |42    |
+---+-------+
```

**‚ö†Ô∏è Laissez ce terminal ouvert et actif**

---

### 7.3 Terminal 3 - Surveiller les Alertes MongoDB

```bash
# Terminal 3
cd /Users/zakariaeelouazzani/Desktop/Projet_charazad

# Se connecter √† MongoDB
docker exec -it mongodb mongo

# Utiliser la base de donn√©es
use logs_analytics

# Surveiller les nouvelles alertes (rafra√Æchir toutes les 10 secondes)
while true; do
  clear
  echo "=== ALERTES D'ERREURS (rafra√Æchi toutes les 10s) ==="
  echo ""
  db.error_alerts.find().sort({detected_at: -1}).limit(5).pretty()
  sleep 10
done
```

**‚úÖ R√©sultat attendu**:

Apr√®s **5-6 minutes**, vous devriez voir des alertes appara√Ætre:

```json
{
    "_id" : ObjectId("..."),
    "alert_type" : "HIGH_500_ERRORS",
    "error_code" : 500,
    "error_count" : 15,
    "threshold" : 10,
    "window_start" : ISODate("2025-02-03T21:00:00Z"),
    "window_end" : ISODate("2025-02-03T21:05:00Z"),
    "detected_at" : ISODate("2025-02-03T21:05:30Z"),
    "severity" : "CRITICAL"
}
{
    "_id" : ObjectId("..."),
    "alert_type" : "HIGH_404_ERRORS",
    "error_code" : 404,
    "error_count" : 42,
    "threshold" : 30,
    "window_start" : ISODate("2025-02-03T21:00:00Z"),
    "window_end" : ISODate("2025-02-03T21:05:00Z"),
    "detected_at" : ISODate("2025-02-03T21:05:30Z"),
    "severity" : "WARNING"
}
```

**üìä V√©rifications**:
- `error_code`: 404 ou 500
- `error_count` > `threshold`
- `alert_type`: HIGH_500_ERRORS ou HIGH_404_ERRORS

---

### 7.4 Arr√™ter les processus de streaming

**Terminal 1** (Producteur Kafka):
- Attendez que les 300 secondes soient √©coul√©es OU
- Appuyez sur `Ctrl+C` puis `exit`

**Terminal 2** (Spark Streaming):
- Appuyez sur `Ctrl+C` (peut prendre 10-20 secondes)

**Terminal 3** (MongoDB):
- Appuyez sur `Ctrl+C`
- Tapez `exit`

---

## üìã √âTAPE 8 - V√©rifier les R√©sultats Finaux

### 8.1 V√©rifier MongoDB

```bash
# Se connecter √† MongoDB
docker exec -it mongodb mongo

# Utiliser la base de donn√©es
use logs_analytics

# Lister toutes les collections
show collections
```

**‚úÖ R√©sultat attendu**:
```
error_alerts
top_products
```

### 8.2 Statistiques Batch

```bash
# Dans MongoDB (toujours connect√©)

# Nombre total de produits analys√©s
db.top_products.count()
# Attendu: 10

# Top 3 produits
db.top_products.find().sort({request_count: -1}).limit(3).pretty()
```

### 8.3 Statistiques Streaming

```bash
# Nombre total d'alertes
db.error_alerts.count()
# Attendu: ‚â• 1 (d√©pend de la dur√©e du test)

# Alertes par type
db.error_alerts.aggregate([
  { $group: { _id: "$alert_type", count: { $sum: 1 } } }
])

# Alertes critiques (500)
db.error_alerts.find({ error_code: 500 }).count()

# Alertes warning (404)
db.error_alerts.find({ error_code: 404 }).count()

# Quitter MongoDB
exit
```

---

## üìã √âTAPE 9 - V√©rifier les Logs Spark

```bash
# Logs du dernier job batch
docker logs spark-master | grep "top_products"

# Logs du job streaming
docker logs spark-master | grep "error_detection"

# Voir toutes les applications Spark
docker exec spark-master curl -s http://localhost:8080/json/ | grep -o '"id":"[^"]*"' | head -5
```

---

## üìã √âTAPE 10 - Tests de Robustesse (Optionnel)

### 10.1 Test: V√©rifier la tol√©rance aux pannes

```bash
# Arr√™ter le DataNode
docker stop datanode

# V√©rifier HDFS (devrait encore fonctionner en mode d√©grad√©)
docker exec namenode hdfs dfs -ls /logs

# Red√©marrer le DataNode
docker start datanode
```

### 10.2 Test: V√©rifier Kafka

```bash
# Lister les topics Kafka
docker exec kafka kafka-topics --list --bootstrap-server localhost:9092

# D√©crire le topic web-logs
docker exec kafka kafka-topics --describe --topic web-logs --bootstrap-server localhost:9092
```

**‚úÖ R√©sultat attendu**:
```
Topic: web-logs
PartitionCount: 1
ReplicationFactor: 1
```

### 10.3 Test: Consommer un message Kafka manuellement

```bash
# Lire les derniers messages du topic
docker exec kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic web-logs \
  --from-beginning \
  --max-messages 5
```

**‚úÖ R√©sultat attendu**: 5 lignes de logs au format standard

---

## üìã √âTAPE 11 - Nettoyage et Arr√™t

### 11.1 Arr√™t propre

```bash
cd /Users/zakariaeelouazzani/Desktop/Projet_charazad

# Arr√™ter tous les services
docker-compose down
```

**‚úÖ R√©sultat attendu**:
```
Stopping mongodb      ... done
Stopping kafka        ... done
Stopping spark-worker ... done
Stopping spark-master ... done
Stopping zookeeper    ... done
Stopping datanode     ... done
Stopping namenode     ... done
Removing mongodb      ... done
Removing kafka        ... done
...
```

### 11.2 Nettoyage complet (si besoin)

```bash
# Supprimer aussi les volumes (‚ö†Ô∏è SUPPRIME LES DONN√âES)
docker-compose down -v

# Supprimer les images non utilis√©es
docker system prune -f
```

---

## üìä CHECKLIST DE VALIDATION FINALE

Cochez chaque test r√©ussi:

### Infrastructure
- [ ] Docker et Docker Compose install√©s
- [ ] 7 conteneurs d√©marr√©s avec succ√®s
- [ ] HDFS accessible (http://localhost:9870)
- [ ] Spark Master accessible (http://localhost:8080)
- [ ] HDFS contient le fichier `/logs/web_server.log`

### Analyse Batch
- [ ] Job Spark batch ex√©cut√© sans erreur
- [ ] 10 produits pr√©sents dans MongoDB (`top_products`)
- [ ] Produits tri√©s par `request_count` d√©croissant
- [ ] Chaque document contient: product_id, product_category, request_count

### Analyse Streaming
- [ ] Producteur Kafka envoie des logs
- [ ] Job Spark Streaming consomme depuis Kafka
- [ ] Alertes g√©n√©r√©es dans MongoDB (`error_alerts`)
- [ ] Alertes contiennent: alert_type, error_code, error_count, threshold
- [ ] Alertes 500 (CRITICAL) et 404 (WARNING) pr√©sentes

### Performance
- [ ] Job batch termin√© en < 2 minutes
- [ ] Job streaming traite les logs en temps r√©el (latence < 10s)
- [ ] Aucune erreur critique dans les logs Docker

---

## üêõ D√âPANNAGE

### Probl√®me: Port d√©j√† utilis√©

```bash
# Trouver le processus utilisant le port 9870
lsof -i :9870

# Tuer le processus
kill -9 <PID>
```

### Probl√®me: HDFS en safe mode

```bash
docker exec namenode hdfs dfsadmin -safemode leave
```

### Probl√®me: Spark ne trouve pas le fichier HDFS

```bash
# V√©rifier la connexion HDFS depuis Spark
docker exec spark-master curl http://namenode:9870/jmx?qry=Hadoop:service=NameNode,name=NameNodeStatus
```

### Probl√®me: Kafka ne d√©marre pas

```bash
# V√©rifier Zookeeper d'abord
docker logs zookeeper | tail -50

# Red√©marrer Kafka
docker restart kafka
```

### Probl√®me: MongoDB n'a pas de donn√©es

```bash
# V√©rifier que MongoDB est accessible depuis Spark
docker exec spark-master nc -zv mongodb 27017
```

---

## üìà R√âSULTATS ATTENDUS - R√âSUM√â

| Test | M√©trique | Valeur Attendue | Statut |
|------|----------|-----------------|--------|
| Services Docker | Conteneurs actifs | 7 | ‚¨ú |
| HDFS | Fichiers stock√©s | 1 (`web_server.log`) | ‚¨ú |
| Batch | Produits dans MongoDB | 10 | ‚¨ú |
| Batch | Dur√©e ex√©cution | < 2 min | ‚¨ú |
| Streaming | Alertes g√©n√©r√©es | ‚â• 1 | ‚¨ú |
| Streaming | Latence traitement | < 10s | ‚¨ú |
| MongoDB | Collections cr√©√©es | 2 | ‚¨ú |

---

## ‚úÖ CONCLUSION

Si tous les tests passent, votre projet Big Data fonctionne parfaitement ! üéâ

**Prochaines √©tapes**:
1. Documentez vos r√©sultats de test dans `RESULTATS_TESTS.md`
2. Prenez des captures d'√©cran des interfaces web
3. Exportez les donn√©es MongoDB pour le rapport

---

**Document cr√©√© le**: 3 F√©vrier 2026  
**Projet**: TP Avanc√© - Analyse de Logs Web  
**Dur√©e totale des tests**: ~30-45 minutes
