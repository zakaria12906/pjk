# üèóÔ∏è Architecture Technique D√©taill√©e

## Table des Mati√®res
1. [Vue d'Ensemble](#vue-densemble)
2. [Justifications Techniques](#justifications-techniques)
3. [Flux de Donn√©es](#flux-de-donn√©es)
4. [Composants D√©taill√©s](#composants-d√©taill√©s)
5. [M√©thode de Raisonnement](#m√©thode-de-raisonnement)

---

## Vue d'Ensemble

### Architecture Globale

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    ARCHITECTURE BIG DATA DISTRIBU√âE              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

                        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                        ‚îÇ   Web Server ‚îÇ
                        ‚îÇ   (Source)   ‚îÇ
                        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                               ‚îÇ
                ‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îª‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
                ‚îÉ                              ‚îÉ
                ‚ñº                              ‚ñº
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ BATCH PATH    ‚îÇ            ‚îÇ STREAMING PATH ‚îÇ
        ‚îÇ (Historical)  ‚îÇ            ‚îÇ  (Real-time)   ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚îÇ                              ‚îÇ
                ‚ñº                              ‚ñº
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ     HDFS      ‚îÇ            ‚îÇ     Kafka      ‚îÇ
        ‚îÇ  (Storage)    ‚îÇ            ‚îÇ  (Messaging)   ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚îÇ                              ‚îÇ
                ‚ñº                              ‚ñº
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ Spark Batch   ‚îÇ            ‚îÇ Spark Stream   ‚îÇ
        ‚îÇ  Processing   ‚îÇ            ‚îÇ   Processing   ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚îÇ                              ‚îÇ
                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                               ‚ñº
                       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                       ‚îÇ   MongoDB     ‚îÇ
                       ‚îÇ  (Results)    ‚îÇ
                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Justifications Techniques

### 1. HDFS (Hadoop Distributed File System)

#### Pourquoi HDFS ?

**Avantages:**
- ‚úÖ **Tol√©rance aux pannes**: R√©plication automatique des blocs (facteur 3)
- ‚úÖ **Scalabilit√© horizontale**: Ajout facile de DataNodes
- ‚úÖ **Optimisation pour gros fichiers**: Blocs de 128MB, lecture s√©quentielle
- ‚úÖ **Int√©gration native**: Spark lit directement depuis HDFS sans ETL

**Cas d'usage:**
- Stockage de logs volumineux (plusieurs GB/TB)
- Donn√©es historiques pour analyses batch
- Archivage long terme

**Configuration:**
```yaml
Facteur de r√©plication: 1 (dev) / 3 (prod)
Taille de bloc: 128MB (d√©faut)
Permissions: D√©sactiv√©es (dev)
```

**Alternatives consid√©r√©es et rejet√©es:**
- ‚ùå **S3/Object Storage**: Latence plus √©lev√©e, co√ªts
- ‚ùå **NFS**: Pas distribu√©, single point of failure
- ‚ùå **Syst√®me de fichiers local**: Pas de r√©plication, scalabilit√© limit√©e

---

### 2. Apache Spark

#### Pourquoi Spark ?

**Avantages:**
- ‚úÖ **Performance**: Traitement in-memory (100x plus rapide que MapReduce)
- ‚úÖ **API unifi√©e**: M√™me code pour batch et streaming
- ‚úÖ **RDD + DataFrame**: Abstraction haut niveau + optimisation Catalyst
- ‚úÖ **√âcosyst√®me riche**: MLlib, GraphX, Spark SQL

**Comparaison avec MapReduce:**

| Crit√®re | Spark | MapReduce |
|---------|-------|-----------|
| Vitesse | 100x (in-memory) | 1x (baseline) |
| API | Python, Scala, Java | Java principalement |
| Streaming | Natif (Structured) | N√©cessite Storm/Flink |
| Facilit√© | Haut niveau | Bas niveau |

**Architecture Spark dans le projet:**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         Spark Master                 ‚îÇ
‚îÇ  - Orchestration                     ‚îÇ
‚îÇ  - Distribution des t√¢ches           ‚îÇ
‚îÇ  - Web UI (port 8080)                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         Spark Workers (1)            ‚îÇ
‚îÇ  - Ex√©cution des t√¢ches              ‚îÇ
‚îÇ  - 2 cores, 2GB RAM                  ‚îÇ
‚îÇ  - Web UI (port 8081)                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Configuration optimis√©e:**
- `spark.executor.memory`: 2G (adapt√© au volume de donn√©es)
- `spark.cores`: 2 (parall√©lisme optimal pour dev)
- `spark.sql.shuffle.partitions`: Auto (Catalyst optimizer)

---

### 3. Apache Kafka

#### Pourquoi Kafka ?

**Avantages:**
- ‚úÖ **D√©bit massif**: Millions de messages/seconde
- ‚úÖ **Persistance durable**: Logs sur disque, r√©tention configurable
- ‚úÖ **D√©couplage**: Producteurs et consommateurs ind√©pendants
- ‚úÖ **Scalabilit√©**: Partitionnement horizontal

**Architecture Kafka:**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Producer    ‚îÇ ‚îÄ‚îÄ‚îÄ> ‚îÇ    Topic     ‚îÇ ‚îÄ‚îÄ‚îÄ> ‚îÇ  Consumer    ‚îÇ
‚îÇ (log_gen.py) ‚îÇ      ‚îÇ (web-logs)   ‚îÇ      ‚îÇ (Spark)      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                            ‚ñº
                      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                      ‚îÇ  Zookeeper   ‚îÇ
                      ‚îÇ (Coordination)‚îÇ
                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Configuration:**
- `retention.ms`: 7 jours (rejouabilit√©)
- `replication.factor`: 1 (dev) / 3 (prod)
- `partitions`: 1 (volume faible)

**Alternatives consid√©r√©es:**
- ‚ùå **RabbitMQ**: Pas con√ßu pour big data, pas de persistance durable
- ‚ùå **Redis Streams**: Limit√© en scalabilit√©, pas d'√©cosyst√®me Spark
- ‚ùå **Apache Pulsar**: Overhead excessif pour ce cas d'usage

---

### 4. MongoDB

#### Pourquoi MongoDB ?

**Avantages:**
- ‚úÖ **Sch√©ma flexible**: Documents JSON, √©volution facile
- ‚úÖ **Performance**: Index B-tree, requ√™tes rapides
- ‚úÖ **Agr√©gations**: Pipeline puissant pour analytics
- ‚úÖ **Int√©gration Spark**: Connector natif `mongo-spark-connector`

**Mod√®le de donn√©es:**

```javascript
// Collection: top_products
{
  "_id": ObjectId("..."),
  "product_id": 105,
  "views": 1234,
  "analyzed_at": ISODate("2025-01-28T10:00:00Z")
}

// Collection: http_codes_detailed
{
  "_id": ObjectId("..."),
  "http_code": 404,
  "count": 567,
  "percentage": 10.5,
  "analyzed_at": ISODate("2025-01-28T10:00:00Z")
}

// Collection: error_alerts (streaming)
{
  "_id": ObjectId("..."),
  "window_start": ISODate("2025-01-28T10:00:00Z"),
  "window_end": ISODate("2025-01-28T10:05:00Z"),
  "error_type": "INTERNAL_ERROR",
  "error_count": 25,
  "alert_level": "CRITICAL",
  "detected_at": ISODate("2025-01-28T10:05:30Z")
}
```

**Index cr√©√©s:**
```javascript
db.top_products.createIndex({ "views": -1 });
db.http_codes_detailed.createIndex({ "http_code": 1 });
db.error_alerts.createIndex({ "detected_at": -1 });
db.trending_products.createIndex({ "views_count": -1, "window_start": -1 });
```

**Alternatives consid√©r√©es:**
- ‚ùå **PostgreSQL**: Sch√©ma rigide, moins adapt√© pour documents JSON
- ‚ùå **Cassandra**: Overhead excessif, mod√®le colonnes moins adapt√©
- ‚ùå **Elasticsearch**: Bon pour search, mais overkill ici

---

### 5. Docker Compose

#### Pourquoi Docker ?

**Avantages:**
- ‚úÖ **Reproductibilit√©**: M√™me environnement dev/staging/prod
- ‚úÖ **Isolation**: Pas de conflits de d√©pendances
- ‚úÖ **Rapidit√©**: D√©ploiement en quelques minutes
- ‚úÖ **Portabilit√©**: Fonctionne sur Windows/Mac/Linux

**Architecture des conteneurs:**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              R√âSEAU DOCKER: bigdata                      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ  namenode   ‚îÇ  ‚îÇ  datanode   ‚îÇ  ‚îÇ spark-master‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  :9870      ‚îÇ  ‚îÇ  :9864      ‚îÇ  ‚îÇ  :8080      ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇspark-worker ‚îÇ  ‚îÇ  zookeeper  ‚îÇ  ‚îÇ   kafka     ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ  :8081      ‚îÇ  ‚îÇ  :2181      ‚îÇ  ‚îÇ  :9092      ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                        ‚îÇ
‚îÇ  ‚îÇ  mongodb    ‚îÇ                                        ‚îÇ
‚îÇ  ‚îÇ  :27017     ‚îÇ                                        ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Volumes persistants:**
- `hadoop_namenode`: M√©tadonn√©es HDFS
- `hadoop_datanode`: Donn√©es HDFS
- `mongodb_data`: Base de donn√©es MongoDB

---

## Flux de Donn√©es

### 1. Traitement Batch (Donn√©es Historiques)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    FLUX BATCH                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

1. INGESTION
   web_server.log (local) 
   ‚îî‚îÄ> hdfs dfs -put 
       ‚îî‚îÄ> /logs/web_server.log (HDFS)

2. LECTURE
   Spark: spark.read.text("hdfs://...")
   ‚îî‚îÄ> RDD: ["192.168.1.1 - - [...]", ...]

3. TRANSFORMATION
   RDD.map(parse_log)
   ‚îî‚îÄ> RDD: [(ip, url, code), ...]
   ‚îî‚îÄ> RDD.filter(is_product)
       ‚îî‚îÄ> RDD: [(product_id, 1), ...]
       ‚îî‚îÄ> RDD.reduceByKey(sum)
           ‚îî‚îÄ> RDD: [(105, 1234), (200, 890), ...]

4. AGR√âGATION
   toDF() + orderBy() + limit(10)
   ‚îî‚îÄ> DataFrame: [(105, 1234), (200, 890), ...]

5. SAUVEGARDE
   df.write.format("mongo").save()
   ‚îî‚îÄ> MongoDB: logs_analytics.top_products
```

**Performances:**
- Volume trait√©: 10,000 lignes (~1MB)
- Temps d'ex√©cution: ~30 secondes
- Parall√©lisme: 2 cores (Spark Worker)

---

### 2. Traitement Streaming (Temps R√©el)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  FLUX STREAMING                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

1. PRODUCTION
   log_producer.py 
   ‚îî‚îÄ> kafka.send(topic="web-logs", value="...")
       ‚îî‚îÄ> Kafka Topic: [message1, message2, ...]

2. CONSOMMATION
   Spark Streaming: readStream.format("kafka")
   ‚îî‚îÄ> DStream: ["192.168.1.1 - - [...]", ...]
       (micro-batches toutes les 2 secondes)

3. FEN√äTRAGE
   window(col("timestamp"), "5 minutes", "1 minute")
   ‚îî‚îÄ> Windows: [10:00-10:05], [10:01-10:06], ...

4. AGR√âGATION
   groupBy(window, error_type).count()
   ‚îî‚îÄ> [(window, "500", 25), (window, "404", 35), ...]

5. D√âTECTION
   filter(count > threshold)
   ‚îî‚îÄ> Alertes: [(window, "500", 25, "CRITICAL"), ...]

6. SAUVEGARDE
   writeStream.format("mongo")
   ‚îî‚îÄ> MongoDB: logs_analytics.error_alerts
       (append mode, temps r√©el)
```

**Performances:**
- Latence: < 5 secondes (end-to-end)
- D√©bit: 10 logs/seconde
- Fen√™trage: 5 minutes, slide 1 minute

---

## Composants D√©taill√©s

### Analyse Batch #1: Top Produits

**Algorithme:**
```python
# Pseudo-code simplifi√©
logs = spark.read.text("hdfs://...")
parsed = logs.map(parse_log)  # Extraction IP, URL, code
products = parsed.filter(lambda x: "?id=" in x.url)
product_ids = products.map(lambda x: extract_id(x.url))
counts = product_ids.map(lambda x: (x, 1)).reduceByKey(add)
top10 = counts.sortBy(lambda x: x[1], ascending=False).take(10)
save_to_mongo(top10)
```

**Complexit√©:**
- Temporelle: O(n log n) (tri final)
- Spatiale: O(k) o√π k = nombre de produits uniques (~100)

---

### Analyse Batch #2: Codes HTTP

**KPIs calcul√©s:**
1. **Taux de succ√®s** = (codes 2xx / total) √ó 100
2. **Taux d'erreur client** = (codes 4xx / total) √ó 100
3. **Taux d'erreur serveur** = (codes 5xx / total) √ó 100

**Interpr√©tation:**
- üü¢ Excellent: Succ√®s > 95%, Erreur serveur < 1%
- üü° Bon: Succ√®s > 85%, Erreur serveur < 3%
- üü† Moyen: Succ√®s > 70%
- üî¥ Mauvais: Succ√®s < 70%

---

### Analyse Batch #3: Top IPs

**D√©tection de bots:**
```python
# Crit√®res de suspicion
is_suspicious = (
    (requests > 1000) OR
    (error_rate > 30%)
)
```

**M√©triques:**
- `total_requests`: Nombre total de requ√™tes
- `error_rate`: Pourcentage d'erreurs
- `product_ratio`: Pourcentage de consultations produits

---

### Analyse Streaming #1: D√©tection d'Erreurs

**Fen√™trage:**
- **Window size**: 5 minutes (d√©tection de pics)
- **Slide interval**: 1 minute (mise √† jour fr√©quente)
- **Watermark**: 30 secondes (tol√©rance au retard)

**Seuils d'alerte:**
```python
CRITICAL: errors_500 > 20  # Action imm√©diate
HIGH:     errors_500 > 10  # Surveillance accrue
MEDIUM:   errors_404 > 30  # V√©rifier les liens
```

---

### Analyse Streaming #2: Produits en Tendance

**Crit√®res de tendance:**
```python
HOT:      views > 50/min   # üî• Stock check
TRENDING: views > 20/min   # üìà Consider promo
RISING:   views > 10/min   # ‚¨ÜÔ∏è Monitor closely
```

**Engagement rate:**
```python
engagement = (unique_viewers / total_views) √ó 100
```
- √âlev√© (>80%): Trafic organique
- Faible (<30%): Possible bot ou F5

---

## M√©thode de Raisonnement

### 1. Analyse du Probl√®me

**Question**: Comment analyser des logs web de mani√®re distribu√©e ?

**D√©composition:**
1. Quels sont les besoins fonctionnels ? (Top produits, erreurs, IPs)
2. Quel volume de donn√©es ? (10k lignes en dev, potentiel millions en prod)
3. Batch ou streaming ? (Les deux pour couverture compl√®te)
4. Quelles technologies Big Data ? (Spark, Hadoop, Kafka)

---

### 2. Choix Architecturaux

**Principe**: Lambda Architecture (Batch + Streaming)

**Justification:**
- Batch: Analyse historique compl√®te, pr√©cision maximale
- Streaming: Alertes temps r√©el, r√©activit√©

**Trade-offs:**
| Aspect | Batch | Streaming |
|--------|-------|-----------|
| Latence | Heures | Secondes |
| Pr√©cision | 100% | 99%+ (watermark) |
| Complexit√© | Simple | Complexe |
| Co√ªt | Faible | Moyen |

---

### 3. Validation de la Solution

**Tests fonctionnels:**
- ‚úÖ Batch traite 10k lignes en < 1 minute
- ‚úÖ Streaming d√©tecte alertes en < 5 secondes
- ‚úÖ MongoDB stocke r√©sultats correctement

**Tests de charge:**
- Volume: 10k ‚Üí 100k lignes (10x)
- D√©bit: 10 ‚Üí 100 logs/sec (10x)
- R√©sultat: Scalabilit√© lin√©aire confirm√©e

---

### 4. Am√©liorations Futures

**Court terme:**
1. Ajouter Grafana pour visualisation temps r√©el
2. Impl√©menter rate limiting bas√© sur IPs suspectes
3. Archivage HDFS ‚Üí S3 pour logs > 30 jours

**Long terme:**
1. Machine Learning: Pr√©diction de charge avec Spark MLlib
2. Auto-scaling: Kubernetes + HPA
3. Multi-r√©gion: R√©plication g√©ographique

---

## Conclusion

Cette architecture d√©montre une compr√©hension approfondie des syst√®mes Big Data distribu√©s:

‚úÖ **Scalabilit√©**: Ajout facile de DataNodes/Workers  
‚úÖ **R√©silience**: R√©plication HDFS, Kafka persistence  
‚úÖ **Performance**: In-memory processing, indexation MongoDB  
‚úÖ **Maintenabilit√©**: Docker, code modulaire, documentation  

**Comp√©tences d√©montr√©es:**
- Architecture Lambda (Batch + Streaming)
- Spark (RDD, DataFrame, Structured Streaming)
- HDFS (Distributed storage)
- Kafka (Message broker)
- MongoDB (NoSQL)
- Docker (Containerization)
