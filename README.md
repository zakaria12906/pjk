# TP AvancÃ© - Analyse de Logs Web avec Architecture Big Data

## Description

Projet d'analyse de logs web d'un site e-commerce de cosmÃ©tiques utilisant une architecture Big Data distribuÃ©e.

**DÃ©pÃ´t GitHub**: https://github.com/zakaria12906/pjk.git

---

## ğŸ“ Structure du Projet

```
Projet_charazad/
â”œâ”€â”€ README.md                          # Ce fichier
â”œâ”€â”€ docker-compose.yml                 # Orchestration des services
â”œâ”€â”€ .gitignore
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ web_server.log                # Fichier de logs (40 lignes)
â”‚
â”œâ”€â”€ spark/
â”‚   â”œâ”€â”€ requirements.txt              # pyspark==3.3.0, pymongo==4.3.3
â”‚   â”œâ”€â”€ batch/
â”‚   â”‚   â””â”€â”€ top_products.py           # Analyse batch: Top 10 produits
â”‚   â””â”€â”€ streaming/
â”‚       â””â”€â”€ error_detection.py        # Analyse streaming: DÃ©tection erreurs
â”‚
â””â”€â”€ kafka/
    â”œâ”€â”€ requirements.txt              # kafka-python==2.0.2
    â””â”€â”€ log_producer.py               # Producteur Kafka
```

---

## ğŸ¯ Analyses ImplÃ©mentÃ©es

### 1. Analyse Batch - Produits les Plus ConsultÃ©s

**Fichier**: `spark/batch/top_products.py`

**Objectif**: Identifier les 10 produits (par leur ID) ayant reÃ§u le plus de requÃªtes.

**Algorithme**:
- Lecture des logs depuis HDFS
- Parsing et extraction des IDs de produits
- Comptage par ID avec MapReduce
- Tri dÃ©croissant et sÃ©lection du Top 10
- Sauvegarde dans MongoDB

**Collection MongoDB**: `logs_analytics.top_products`

---

### 2. Analyse Streaming - DÃ©tection d'Erreurs en Temps RÃ©el

**Fichier**: `spark/streaming/error_detection.py`

**Objectif**: Surveiller les logs pour dÃ©tecter des pics d'erreurs (codes 404 ou 500) sur un intervalle de 5 minutes.

**MÃ©thode**:
- Consommation depuis Kafka (topic: `web-logs`)
- FenÃªtrage temporel: 5 minutes (slide 1 minute)
- Filtrage des codes 404 et 500
- GÃ©nÃ©ration d'alertes si:
  - Erreurs 500 > 10
  - Erreurs 404 > 30
- Sauvegarde des alertes dans MongoDB

**Collection MongoDB**: `logs_analytics.error_alerts`

---

## ğŸ—ï¸ Architecture Big Data

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Web Server  â”‚ -->  â”‚    HDFS      â”‚ -->  â”‚ Spark Batch  â”‚
â”‚   (Logs)     â”‚      â”‚  (Storage)   â”‚      â”‚  Processing  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                                    â”‚
                                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Log Producer â”‚ -->  â”‚    Kafka     â”‚ -->  â”‚Spark Stream  â”‚
â”‚  (Simulator) â”‚      â”‚  (Streaming) â”‚      â”‚  Processing  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                                    â”‚
                                                    â–¼
                                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                            â”‚   MongoDB    â”‚
                                            â”‚  (Results)   â”‚
                                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Services Docker

| Service | Image | Port | RÃ´le |
|---------|-------|------|------|
| namenode | bde2020/hadoop-namenode:2.0.0 | 9870, 9000 | HDFS NameNode |
| datanode | bde2020/hadoop-datanode:2.0.0 | 9864 | HDFS DataNode |
| spark-master | bitnami/spark:3.3.0 | 8080, 7077 | Spark Master |
| spark-worker | bitnami/spark:3.3.0 | 8081 | Spark Worker |
| zookeeper | confluentinc/cp-zookeeper:7.3.0 | 2181 | Coordination |
| kafka | confluentinc/cp-kafka:7.3.0 | 9092, 9093 | Message Broker |
| mongodb | mongo:6.0 | 27017 | Base de donnÃ©es |

---

## ğŸš€ Installation et ExÃ©cution

### PrÃ©requis
- Docker >= 20.10
- Docker Compose >= 2.0
- 8GB RAM minimum
- Python 3.7+

### 1. DÃ©marrer les services

```bash
cd /Users/zakariaeelouazzani/Desktop/Projet_charazad

docker-compose up -d

# VÃ©rifier que tous les services sont dÃ©marrÃ©s
docker-compose ps
```

**Attendez ~2 minutes que tous les services soient prÃªts.**

### 2. PrÃ©parer HDFS

```bash
# CrÃ©er les rÃ©pertoires dans HDFS
docker exec namenode hdfs dfs -mkdir -p /logs
docker exec namenode hdfs dfs -chmod -R 777 /logs

# Copier les logs dans HDFS
docker exec namenode hdfs dfs -put /data/web_server.log /logs/

# VÃ©rifier
docker exec namenode hdfs dfs -ls /logs
```

### 3. ExÃ©cuter l'analyse Batch

```bash
docker exec spark-master spark-submit \
  --master spark://spark-master:7077 \
  --packages org.mongodb.spark:mongo-spark-connector_2.12:3.0.1 \
  /spark-apps/batch/top_products.py
```

**Consulter les rÃ©sultats**:
```bash
docker exec -it mongodb mongo
> use logs_analytics
> db.top_products.find().pretty()
```

### 4. ExÃ©cuter l'analyse Streaming

**Terminal 1 - DÃ©marrer le producteur Kafka**:
```bash
docker exec -it kafka bash
cd /kafka-apps
python3 log_producer.py

# Dans le menu, choisir:
# 2. ERRORS (pour tester la dÃ©tection d'erreurs)
# DurÃ©e: 300 secondes
```

**Terminal 2 - DÃ©marrer Spark Streaming**:
```bash
docker exec spark-master spark-submit \
  --master spark://spark-master:7077 \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0,org.mongodb.spark:mongo-spark-connector_2.12:3.0.1 \
  /spark-apps/streaming/error_detection.py
```

**Terminal 3 - Consulter les alertes**:
```bash
docker exec -it mongodb mongo
> use logs_analytics
> db.error_alerts.find().sort({detected_at: -1}).pretty()
```

---

## ğŸ“Š Interfaces Web

| Service | URL | Description |
|---------|-----|-------------|
| HDFS NameNode | http://localhost:9870 | Interface web HDFS |
| Spark Master | http://localhost:8080 | Interface Spark Master |
| Spark Worker | http://localhost:8081 | Ã‰tat Worker |

---

## ğŸ›‘ ArrÃªter les Services

```bash
docker-compose down
```

Pour supprimer Ã©galement les volumes (donnÃ©es):
```bash
docker-compose down -v
```

---

## ğŸ› ï¸ Technologies UtilisÃ©es

- **HDFS** 3.2.1 - Stockage distribuÃ©
- **Apache Spark** 3.3.0 - Traitement batch et streaming
- **Apache Kafka** 7.3.0 - Streaming de donnÃ©es
- **Zookeeper** 7.3.0 - Coordination
- **MongoDB** 6.0 - Stockage des rÃ©sultats
- **Docker** & **Docker Compose** - Orchestration

---

## ğŸ“ Justifications Techniques

### Pourquoi HDFS ?
- TolÃ©rance aux pannes (rÃ©plication)
- ScalabilitÃ© horizontale
- IntÃ©gration native avec Spark

### Pourquoi Spark ?
- Performance in-memory (100x MapReduce)
- API unifiÃ©e batch + streaming
- Support Python (PySpark)

### Pourquoi Kafka ?
- DÃ©bit massif
- Persistance durable
- DÃ©couplage producteur/consommateur

### Pourquoi MongoDB ?
- SchÃ©ma flexible (JSON)
- Performance avec index
- Connector Spark natif

---

## ğŸ“š Livrables

ConformÃ©ment au sujet du TP, ce projet contient:

1. âœ… **Code source des traitements Spark**:
   - `spark/batch/top_products.py`
   - `spark/streaming/error_detection.py`

2. âœ… **Fichier docker-compose.yml**:
   - Orchestration de 7 services (Hadoop, Spark, Kafka, MongoDB)

3. âœ… **Architecture distribuÃ©e fonctionnelle**:
   - HDFS pour stockage
   - Spark pour traitement (batch + stream)
   - Communication inter-services vÃ©rifiÃ©e

---

## ğŸ› DÃ©pannage

### Port dÃ©jÃ  utilisÃ©
```bash
lsof -i :9870
kill -9 <PID>
```

### HDFS en safe mode
```bash
docker exec namenode hdfs dfsadmin -safemode leave
```

### Voir les logs
```bash
docker logs -f spark-master
docker logs -f kafka
```

---

## ğŸ“¦ DÃ©pÃ´t GitHub

**URL**: https://github.com/zakaria12906/pjk.git

```bash
git clone https://github.com/zakaria12906/pjk.git
cd pjk
```

---

**Projet rÃ©alisÃ© dans le cadre du TP AvancÃ© - Big Data**
