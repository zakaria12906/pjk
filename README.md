# üöÄ Projet Charazad - Architecture Big Data pour l'Analyse de Logs Web

## üìã Description

Projet d'analyse de logs web utilisant une architecture Big Data distribu√©e avec Docker. Le syst√®me analyse les logs d'un site e-commerce de cosm√©tiques en utilisant **Apache Spark** (batch et streaming), **HDFS**, **Kafka**, et **MongoDB**.

**D√©p√¥t GitHub**: https://github.com/zakaria12906/pjk.git

---

## üéØ Fonctionnalit√©s

### üìä Analyses Batch (Donn√©es Historiques)
1. **Top 10 Produits** - Produits les plus consult√©s
2. **Codes HTTP** - KPIs de sant√© du serveur (taux de succ√®s, erreurs)
3. **Top 10 IPs** - IPs les plus actives avec d√©tection de bots

### ‚ö° Analyses Streaming (Temps R√©el)
1. **D√©tection d'Erreurs** - Alertes sur pics d'erreurs 404/500 (fen√™tre 5 min)
2. **Produits Tendance** - Produits populaires en temps r√©el (>20 vues/min)

---

## üèóÔ∏è Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Web Server  ‚îÇ -->  ‚îÇ    HDFS      ‚îÇ -->  ‚îÇ Spark Batch  ‚îÇ
‚îÇ   (Logs)     ‚îÇ      ‚îÇ  (Storage)   ‚îÇ      ‚îÇ  Processing  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                    ‚îÇ
                                                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Log Producer ‚îÇ -->  ‚îÇ    Kafka     ‚îÇ -->  ‚îÇSpark Stream  ‚îÇ
‚îÇ  (Simulator) ‚îÇ      ‚îÇ  (Streaming) ‚îÇ      ‚îÇ  Processing  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                    ‚îÇ
                                                    ‚ñº
                                            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                            ‚îÇ   MongoDB    ‚îÇ
                                            ‚îÇ  (Results)   ‚îÇ
                                            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Services Docker:**
- **HDFS**: NameNode (9870) + DataNode (9864)
- **Spark**: Master (8080, 7077) + Worker (8081)
- **Kafka**: Broker (9092, 9093) + Zookeeper (2181)
- **MongoDB**: Database (27017)

---

## üìÅ Structure du Projet

```
Projet_charazad/
‚îú‚îÄ‚îÄ README.md                      # Ce fichier
‚îú‚îÄ‚îÄ ARCHITECTURE.md                # Justifications techniques d√©taill√©es
‚îú‚îÄ‚îÄ QUICKSTART.md                  # Guide d√©marrage rapide (10 min)
‚îú‚îÄ‚îÄ LIVRABLE.md                    # Document de livraison
‚îú‚îÄ‚îÄ INDEX.md                       # Navigation dans le projet
‚îú‚îÄ‚îÄ docker-compose.yml             # Orchestration des services
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ web_server.log            # Logs d'exemple (40 lignes)
‚îÇ   ‚îî‚îÄ‚îÄ generate_logs.py          # G√©n√©rateur de logs (10k lignes)
‚îÇ
‚îú‚îÄ‚îÄ spark/
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt          # pyspark, pymongo
‚îÇ   ‚îú‚îÄ‚îÄ batch/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ top_products.py       # Analyse #1: Top produits
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ http_codes.py         # Analyse #2: Codes HTTP
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ top_ips.py            # Analyse #3: Top IPs
‚îÇ   ‚îî‚îÄ‚îÄ streaming/
‚îÇ       ‚îú‚îÄ‚îÄ error_detection.py    # Streaming #1: D√©tection erreurs
‚îÇ       ‚îî‚îÄ‚îÄ trending_products.py  # Streaming #2: Produits tendance
‚îÇ
‚îú‚îÄ‚îÄ kafka/
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt          # kafka-python
‚îÇ   ‚îî‚îÄ‚îÄ log_producer.py           # Producteur Kafka (simulation)
‚îÇ
‚îî‚îÄ‚îÄ scripts/
    ‚îú‚îÄ‚îÄ setup.sh                  # Configuration initiale
    ‚îú‚îÄ‚îÄ prepare_hdfs.sh           # Pr√©paration HDFS
    ‚îú‚îÄ‚îÄ run_batch.sh              # Lancer analyses batch
    ‚îú‚îÄ‚îÄ run_streaming.sh          # Guide streaming
    ‚îú‚îÄ‚îÄ stop.sh                   # Arr√™ter les services
    ‚îî‚îÄ‚îÄ clean.sh                  # Nettoyage complet
```

---

## üöÄ Installation et D√©marrage Rapide

### Pr√©requis
- Docker >= 20.10
- Docker Compose >= 2.0
- 8GB RAM minimum
- 20GB espace disque
- Python 3.7+

### D√©marrage en 5 √âtapes (10 minutes)

#### 1. Configuration initiale (2 min)
```bash
cd /Users/zakariaeelouazzani/Desktop/Projet_charazad
chmod +x scripts/*.sh
./scripts/setup.sh
```

#### 2. D√©marrer les services (3 min)
```bash
docker-compose up -d

# V√©rifier que tous les services sont actifs
docker-compose ps
```

**Attendez ~2 minutes que tous les services d√©marrent.**

#### 3. Pr√©parer HDFS (1 min)
```bash
./scripts/prepare_hdfs.sh
```

#### 4. Lancer les analyses batch (2 min)
```bash
./scripts/run_batch.sh
```

Cela lance s√©quentiellement:
- Top 10 Produits (~30s)
- R√©partition Codes HTTP (~30s)
- Top 10 IPs Actives (~30s)

#### 5. Consulter les r√©sultats (1 min)
```bash
docker exec -it mongodb mongo

# Dans le shell MongoDB:
use logs_analytics
show collections

# Voir les r√©sultats
db.top_products.find().pretty()
db.http_codes_detailed.find().pretty()
db.top_ips.find().pretty()
```

---

## üìä Interfaces Web

| Service | URL | Description |
|---------|-----|-------------|
| HDFS NameNode | http://localhost:9870 | Browse HDFS files |
| HDFS DataNode | http://localhost:9864 | DataNode status |
| Spark Master | http://localhost:8080 | Cluster overview |
| Spark Worker | http://localhost:8081 | Worker status |

---

## ‚ö° Tester le Streaming (Optionnel)

### Terminal 1: Producteur Kafka
```bash
docker exec -it kafka bash
cd /kafka-apps
python3 log_producer.py

# Dans le menu:
# 1. Choisir "2" pour mode ERRORS (pic d'erreurs)
# 2. Dur√©e: 300 secondes (5 minutes)
```

### Terminal 2: D√©tection d'erreurs
```bash
docker exec -it spark-master bash

spark-submit \
  --master spark://spark-master:7077 \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0,org.mongodb.spark:mongo-spark-connector_2.12:3.0.1 \
  /spark-apps/streaming/error_detection.py
```

### Terminal 3: Voir les alertes
```bash
docker exec -it mongodb mongo

use logs_analytics
# Rafra√Æchir toutes les 5 secondes
db.error_alerts.find().sort({detected_at: -1}).limit(5).pretty()
```

---

## üõë Arr√™ter les Services

```bash
./scripts/stop.sh

# OU directement
docker-compose down
```

---

## üßπ Nettoyage Complet

**‚ö†Ô∏è ATTENTION: Supprime toutes les donn√©es !**

```bash
./scripts/clean.sh
```

---

## üêõ D√©pannage

### Erreur: "Cannot connect to Docker daemon"
```bash
# D√©marrer Docker Desktop (Mac/Windows)
# OU sur Linux:
sudo systemctl start docker
```

### Erreur: "Port already in use"
```bash
# Trouver le processus (exemple: 9870)
lsof -i :9870
kill -9 <PID>
```

### Erreur: "HDFS in safe mode"
```bash
docker exec namenode hdfs dfsadmin -safemode leave
```

### Spark job √©choue avec OutOfMemory
```bash
# Augmenter la m√©moire dans docker-compose.yml
SPARK_WORKER_MEMORY=4G  # au lieu de 2G
docker-compose restart spark-worker
```

---

## üõ†Ô∏è Justifications Techniques

### Pourquoi HDFS ?
- ‚úÖ Tol√©rance aux pannes (r√©plication)
- ‚úÖ Scalabilit√© horizontale
- ‚úÖ Int√©gration native avec Spark
- ‚úÖ Optimis√© pour gros fichiers

### Pourquoi Spark ?
- ‚úÖ Performance in-memory (100x MapReduce)
- ‚úÖ API unifi√©e batch + streaming
- ‚úÖ √âcosyst√®me riche (MLlib, SQL)
- ‚úÖ Support Python (PySpark)

### Pourquoi Kafka ?
- ‚úÖ D√©bit massif (millions msg/sec)
- ‚úÖ Persistance durable
- ‚úÖ D√©couplage producteur/consommateur
- ‚úÖ Rejouabilit√© des messages

### Pourquoi MongoDB ?
- ‚úÖ Sch√©ma flexible (JSON)
- ‚úÖ Performance (index B-tree)
- ‚úÖ Agr√©gations puissantes
- ‚úÖ Connector Spark natif

Pour plus de d√©tails, voir **[ARCHITECTURE.md](ARCHITECTURE.md)**.

---

## üìö Documentation

- **[QUICKSTART.md](QUICKSTART.md)** - Guide de d√©marrage rapide (10 min)
- **[ARCHITECTURE.md](ARCHITECTURE.md)** - Justifications techniques compl√®tes
- **[LIVRABLE.md](LIVRABLE.md)** - Document de livraison acad√©mique
- **[INDEX.md](INDEX.md)** - Navigation et index du projet

---

## üí° Commandes Utiles

### Logs des conteneurs
```bash
docker logs -f spark-master     # Logs Spark
docker logs -f kafka            # Logs Kafka
docker logs -f namenode         # Logs HDFS
```

### √âtat du cluster
```bash
docker-compose ps               # √âtat des conteneurs
docker stats                    # Usage CPU/RAM
docker exec namenode hdfs dfsadmin -report  # √âtat HDFS
```

### Shell interactif
```bash
docker exec -it spark-master bash   # Shell Spark
docker exec -it namenode bash       # Shell Hadoop
docker exec -it mongodb mongo       # Shell MongoDB
```

---

## ‚úÖ Checklist de Validation

Avant de consid√©rer le projet comme fonctionnel:

- [ ] Tous les conteneurs sont en √©tat "Up" (`docker-compose ps`)
- [ ] HDFS contient le fichier de logs (`hdfs dfs -ls /logs`)
- [ ] Les 3 analyses batch s'ex√©cutent sans erreur
- [ ] Les r√©sultats sont visibles dans MongoDB
- [ ] Les interfaces web sont accessibles
- [ ] Le streaming fonctionne (optionnel)

---

## üéì Objectifs P√©dagogiques

En compl√©tant ce projet, vous aurez ma√Ætris√©:

‚úÖ Architecture distribu√©e avec Docker  
‚úÖ HDFS pour stockage distribu√©  
‚úÖ Spark Batch (RDD, DataFrame)  
‚úÖ Spark Structured Streaming  
‚úÖ Kafka pour streaming de donn√©es  
‚úÖ MongoDB pour NoSQL  
‚úÖ Int√©gration compl√®te de l'√©cosyst√®me Big Data

---

## üìä Tests et Documentation de Test

Le dossier contient √©galement des guides de test pour l'application web:

- **GUIDE_TEST_ETAPES.md** - Guide de test √©tape par √©tape
- **RESUME_API.md** - R√©sum√© des endpoints API
- **RESULTATS_TESTS.md** - Template pour r√©sultats de tests

Ces fichiers documentent comment tester l'application web dont les logs sont analys√©s.

---

## üë®‚Äçüíª Auteur

Projet r√©alis√© dans le cadre du cours de Big Data et Data Engineering.

**D√©p√¥t GitHub**: https://github.com/zakaria12906/pjk.git

---

## üìù Licence

MIT License - Usage acad√©mique et √©ducatif.

---

**Bon courage ! üöÄ**

*Pour un d√©marrage ultra-rapide, consultez [QUICKSTART.md](QUICKSTART.md)*
