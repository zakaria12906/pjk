# üì¶ PROJET COMPLET - Organisation et D√©marrage

## ‚úÖ Organisation Termin√©e

Tous les fichiers ont √©t√© organis√©s dans le projet `Projet_charazad`.

---

## üìÅ Structure Compl√®te

```
Projet_charazad/
‚îÇ
‚îú‚îÄ‚îÄ üìÑ README.md                      # Documentation principale (NOUVEAU)
‚îú‚îÄ‚îÄ üìÑ ARCHITECTURE.md                # Justifications techniques d√©taill√©es
‚îú‚îÄ‚îÄ üìÑ QUICKSTART.md                  # Guide d√©marrage rapide (10 min)
‚îú‚îÄ‚îÄ üìÑ LIVRABLE.md                    # Document de livraison acad√©mique
‚îú‚îÄ‚îÄ üìÑ INDEX.md                       # Navigation dans le projet
‚îú‚îÄ‚îÄ üìÑ PROJET_COMPLET.md              # Ce fichier
‚îÇ
‚îú‚îÄ‚îÄ üê≥ docker-compose.yml             # Orchestration des 7 services
‚îú‚îÄ‚îÄ üìù .gitignore                     # Fichiers √† ignorer (mis √† jour)
‚îÇ
‚îú‚îÄ‚îÄ üìÇ data/                          # Donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ web_server.log               # Logs d'exemple (40 lignes)
‚îÇ   ‚îî‚îÄ‚îÄ generate_logs.py             # G√©n√©rateur de logs (10k lignes)
‚îÇ
‚îú‚îÄ‚îÄ üìÇ spark/                         # Applications Spark
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt             # pyspark==3.3.0, pymongo==4.3.3
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ batch/                    # Analyses Batch
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ top_products.py          # ‚úÖ Top 10 produits
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ http_codes.py            # ‚úÖ Codes HTTP + KPIs
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ top_ips.py               # ‚úÖ Top 10 IPs + d√©tection bots
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ üìÇ streaming/                # Analyses Streaming
‚îÇ       ‚îú‚îÄ‚îÄ error_detection.py       # ‚úÖ D√©tection erreurs temps r√©el
‚îÇ       ‚îî‚îÄ‚îÄ trending_products.py     # ‚úÖ Produits en tendance
‚îÇ
‚îú‚îÄ‚îÄ üìÇ kafka/                         # Kafka
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt             # kafka-python==2.0.2
‚îÇ   ‚îî‚îÄ‚îÄ log_producer.py              # Producteur Kafka (simulation)
‚îÇ
‚îî‚îÄ‚îÄ üìÇ scripts/                       # Scripts utilitaires
    ‚îú‚îÄ‚îÄ setup.sh                     # ‚úÖ Configuration initiale
    ‚îú‚îÄ‚îÄ prepare_hdfs.sh              # ‚úÖ Pr√©paration HDFS
    ‚îú‚îÄ‚îÄ run_batch.sh                 # ‚úÖ Lancer analyses batch
    ‚îú‚îÄ‚îÄ run_streaming.sh             # ‚úÖ Guide streaming
    ‚îú‚îÄ‚îÄ stop.sh                      # ‚úÖ Arr√™ter services
    ‚îî‚îÄ‚îÄ clean.sh                     # ‚úÖ Nettoyage complet
```

**Total**: 27 fichiers organis√©s

---

## üöÄ Comment D√©marrer le Projet ?

### Option 1: D√©marrage Rapide (10 minutes)

Suivez le guide **[QUICKSTART.md](QUICKSTART.md)** qui vous guide √©tape par √©tape.

### Option 2: Commandes Directes

```bash
# 1. Se placer dans le projet
cd /Users/zakariaeelouazzani/Desktop/Projet_charazad

# 2. Configuration initiale
chmod +x scripts/*.sh
./scripts/setup.sh

# 3. D√©marrer les services Docker
docker-compose up -d

# 4. Attendre ~2 minutes, puis pr√©parer HDFS
./scripts/prepare_hdfs.sh

# 5. Lancer les analyses batch
./scripts/run_batch.sh

# 6. Consulter les r√©sultats
docker exec -it mongodb mongo
> use logs_analytics
> db.top_products.find().pretty()
```

---

## üìä Services Disponibles

Une fois d√©marr√©, vous avez acc√®s √† :

| Service | URL | Description |
|---------|-----|-------------|
| **HDFS NameNode** | http://localhost:9870 | Interface web HDFS |
| **HDFS DataNode** | http://localhost:9864 | √âtat DataNode |
| **Spark Master** | http://localhost:8080 | Interface Spark Master |
| **Spark Worker** | http://localhost:8081 | √âtat Worker |
| **MongoDB** | localhost:27017 | Base de donn√©es (CLI) |
| **Kafka** | localhost:9092 | Broker Kafka (CLI) |
| **Zookeeper** | localhost:2181 | Coordination (CLI) |

---

## üéØ Analyses Disponibles

### Batch (Donn√©es Historiques)

| # | Analyse | Fichier | Objectif | Temps |
|---|---------|---------|----------|-------|
| 1 | Top Produits | `spark/batch/top_products.py` | 10 produits les plus consult√©s | ~30s |
| 2 | Codes HTTP | `spark/batch/http_codes.py` | KPIs sant√© serveur | ~30s |
| 3 | Top IPs | `spark/batch/top_ips.py` | IPs actives + d√©tection bots | ~30s |

### Streaming (Temps R√©el)

| # | Analyse | Fichier | Objectif | Fen√™tre |
|---|---------|---------|----------|---------|
| 1 | D√©tection Erreurs | `spark/streaming/error_detection.py` | Alertes erreurs 404/500 | 5 min |
| 2 | Produits Tendance | `spark/streaming/trending_products.py` | Produits populaires (>20/min) | 1 min |

---

## üìö Documentation

### Pour D√©marrer
- **[README.md](README.md)** - Documentation principale avec instructions compl√®tes
- **[QUICKSTART.md](QUICKSTART.md)** - D√©marrage en 10 minutes

### Pour Approfondir
- **[ARCHITECTURE.md](ARCHITECTURE.md)** - Justifications techniques, flux de donn√©es, algorithmes
- **[LIVRABLE.md](LIVRABLE.md)** - Document de livraison acad√©mique
- **[INDEX.md](INDEX.md)** - Navigation et index complet

### Pour Tester
- **[GUIDE_TEST_ETAPES.md](GUIDE_TEST_ETAPES.md)** - Tests de l'application web
- **[RESUME_API.md](RESUME_API.md)** - R√©sum√© des endpoints API
- **[RESULTATS_TESTS.md](RESULTATS_TESTS.md)** - Template r√©sultats

---

## üîß Technologies Utilis√©es

### Stockage et Traitement
- **HDFS** 3.2.1 - Stockage distribu√©
- **Apache Spark** 3.3.0 - Traitement batch et streaming
- **Apache Kafka** 7.3.0 - Streaming de donn√©es
- **Zookeeper** 7.3.0 - Coordination

### Stockage R√©sultats
- **MongoDB** 6.0 - Base NoSQL

### Infrastructure
- **Docker** & **Docker Compose** - Orchestration

### Langages
- **Python** 3.7+ - PySpark, scripts

---

## üéì Comp√©tences D√©montr√©es

‚úÖ Architecture distribu√©e Lambda (Batch + Streaming)  
‚úÖ HDFS pour stockage distribu√©  
‚úÖ Spark RDD et DataFrame  
‚úÖ Spark Structured Streaming  
‚úÖ Kafka pour messaging  
‚úÖ MongoDB pour NoSQL  
‚úÖ Docker pour containerization  
‚úÖ Windowing et Watermarking  
‚úÖ Parsing et regex  
‚úÖ Agr√©gations et transformations  

---

## üíæ Enregistrer sur GitHub

Le projet est d√©j√† initialis√© avec Git et configur√© pour le repo :
**https://github.com/zakaria12906/pjk.git**

Pour pousser les nouveaux fichiers Big Data :

```bash
cd /Users/zakariaeelouazzani/Desktop/Projet_charazad

# Ajouter les fichiers Big Data
git add docker-compose.yml
git add data/ spark/ kafka/ scripts/
git add ARCHITECTURE.md QUICKSTART.md LIVRABLE.md INDEX.md
git add README.md

# Commit
git commit -m "Ajout architecture Big Data compl√®te avec Spark, HDFS, Kafka, MongoDB"

# Push
git push origin main
```

---

## ‚úÖ Checklist de Validation

Avant de commencer √† utiliser le projet :

- [ ] Docker Desktop est install√© et d√©marr√©
- [ ] Au moins 8GB RAM disponible
- [ ] Ports 9870, 9864, 8080, 8081, 27017, 9092, 2181 libres
- [ ] Scripts rendus ex√©cutables (`chmod +x scripts/*.sh`)

Pour valider que tout fonctionne :

- [ ] `docker-compose ps` montre 7 conteneurs "Up"
- [ ] http://localhost:9870 accessible (HDFS)
- [ ] http://localhost:8080 accessible (Spark)
- [ ] Les 3 analyses batch s'ex√©cutent sans erreur
- [ ] Les r√©sultats apparaissent dans MongoDB

---

## üêõ En Cas de Probl√®me

### Ports d√©j√† utilis√©s
```bash
# Trouver le processus
lsof -i :9870

# Tuer le processus
kill -9 <PID>
```

### Conteneurs qui ne d√©marrent pas
```bash
# Voir les logs
docker logs -f <nom_conteneur>

# Red√©marrer
docker-compose restart <nom_conteneur>
```

### Nettoyage complet
```bash
./scripts/clean.sh
# Puis recommencer depuis le d√©but
```

### Besoin d'aide
1. Consulter [QUICKSTART.md](QUICKSTART.md) - Section "D√©pannage"
2. V√©rifier les logs : `docker logs -f <service>`
3. Consulter [ARCHITECTURE.md](ARCHITECTURE.md) pour comprendre le fonctionnement

---

## üéâ F√©licitations !

Vous avez maintenant un projet Big Data complet et op√©rationnel avec :

‚úÖ 7 services distribu√©s orchestr√©s  
‚úÖ 5 analyses (3 batch + 2 streaming)  
‚úÖ Documentation compl√®te (6 fichiers MD)  
‚úÖ Scripts d'automatisation (6 scripts)  
‚úÖ Int√©gration GitHub configur√©e  

**Pr√™t pour la production et les tests ! üöÄ**

---

*Document cr√©√© le 3 F√©vrier 2026*  
*Projet: Architecture Big Data Distribu√©e*
