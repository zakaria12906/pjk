#!/bin/bash
################################################################################
# Script de Lancement du Streaming
# Guide l'utilisateur pour lancer les analyses streaming
################################################################################

echo "=========================================="
echo "âš¡ GUIDE DE LANCEMENT DU STREAMING"
echo "=========================================="
echo ""
echo "Pour tester les analyses streaming, vous devez:"
echo ""
echo "1ï¸âƒ£  DÃ©marrer le producteur Kafka (dans un terminal):"
echo "   docker exec -it kafka bash"
echo "   cd /kafka-apps"
echo "   python3 log_producer.py"
echo ""
echo "2ï¸âƒ£  DÃ©marrer l'analyse d'erreurs (dans un 2Ã¨me terminal):"
echo "   docker exec -it spark-master bash"
echo "   spark-submit \\"
echo "     --master spark://spark-master:7077 \\"
echo "     --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0,org.mongodb.spark:mongo-spark-connector_2.12:3.0.1 \\"
echo "     /spark-apps/streaming/error_detection.py"
echo ""
echo "3ï¸âƒ£  DÃ©marrer l'analyse des tendances (dans un 3Ã¨me terminal):"
echo "   docker exec -it spark-master bash"
echo "   spark-submit \\"
echo "     --master spark://spark-master:7077 \\"
echo "     --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0,org.mongodb.spark:mongo-spark-connector_2.12:3.0.1 \\"
echo "     /spark-apps/streaming/trending_products.py"
echo ""
echo "ðŸ“Š Consulter les rÃ©sultats en temps rÃ©el:"
echo "   docker exec -it mongodb mongo"
echo "   > use logs_analytics"
echo "   > db.error_alerts.find().pretty()"
echo "   > db.trending_products.find().pretty()"
echo ""
echo "ðŸ’¡ Astuce: Dans le producteur Kafka, choisissez:"
echo "   - Mode ERRORS pour tester les alertes d'erreurs"
echo "   - Mode TRENDING pour tester la dÃ©tection de tendances"
echo ""
