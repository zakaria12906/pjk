# üöÄ Architecture Distribu√©e pour l'Analyse de Logs Web

## üìã Description du Projet

Projet d'analyse de logs web d'un site e-commerce sp√©cialis√© dans les cosm√©tiques utilisant une architecture Big Data distribu√©e avec Docker.

### Technologies Utilis√©es
- **HDFS**: Stockage distribu√© des logs
- **Apache Spark**: Traitement batch et streaming
- **Apache Kafka**: Streaming de donn√©es en temps r√©el
- **MongoDB**: Stockage des r√©sultats d'analyses
- **Docker & Docker Compose**: Orchestration des conteneurs

---

## üéØ Analyses Impl√©ment√©es

### üìä Analyses Batch (sur donn√©es statiques)
1. **Top 10 Produits les plus consult√©s**
   - Identifie les produits ayant re√ßu le plus de requ√™tes
   - Output: ID produit + nombre de consultations

2. **R√©partition des Codes HTTP**
   - Analyse la fr√©quence des codes HTTP (200, 404, 500, etc.)
   - KPI de sant√© du serveur

3. **Top 10 Adresses IP les plus actives**
   - Identifie les IPs g√©n√©rant le plus de requ√™tes
   - D√©tection d'activit√© suspecte (bots, DDoS)

### ‚ö° Analyses Streaming (temps r√©el)
1. **D√©tection d'erreurs en temps r√©el**
   - Surveillance des pics d'erreurs 404/500
   - Alerte si > 10 erreurs sur une fen√™tre de 5 minutes

2. **Produits en tendance**
   - Identification des produits populaires en temps r√©el
   - Alerte si > 20 consultations en 1 minute

---

## üèóÔ∏è Architecture Technique

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     ARCHITECTURE BIG DATA                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Web Server  ‚îÇ -->  ‚îÇ    HDFS      ‚îÇ -->  ‚îÇ Spark Batch  ‚îÇ
‚îÇ   (Logs)     ‚îÇ      ‚îÇ  (Storage)   ‚îÇ      ‚îÇ  Processing  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                                     ‚îÇ
                                                     ‚ñº
                                            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ   MongoDB    ‚îÇ
‚îÇ Log Producer ‚îÇ -->  ‚îÇ    Kafka     ‚îÇ     ‚îÇ  (Results)   ‚îÇ
‚îÇ  (Simulator) ‚îÇ      ‚îÇ  (Streaming) ‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚ñ≤
                             ‚îÇ                      ‚îÇ
                             ‚ñº                      ‚îÇ
                      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îÇ
                      ‚îÇSpark Stream  ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ  Processing  ‚îÇ
                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìÅ Structure du Projet

```
bigdata-logs-analysis/
‚îú‚îÄ‚îÄ docker-compose.yml              # Orchestration des conteneurs
‚îú‚îÄ‚îÄ README.md                       # Documentation
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ web_server.log             # Fichier de logs exemple
‚îÇ   ‚îî‚îÄ‚îÄ generate_logs.py           # G√©n√©rateur de logs
‚îú‚îÄ‚îÄ spark/
‚îÇ   ‚îú‚îÄ‚îÄ batch/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ top_products.py        # Analyse: Produits populaires
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ http_codes.py          # Analyse: Codes HTTP
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ top_ips.py             # Analyse: IPs actives
‚îÇ   ‚îú‚îÄ‚îÄ streaming/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ error_detection.py     # Streaming: D√©tection erreurs
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ trending_products.py   # Streaming: Produits tendance
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt            # D√©pendances Python
‚îú‚îÄ‚îÄ kafka/
‚îÇ   ‚îî‚îÄ‚îÄ log_producer.py            # Producteur Kafka pour simulation
‚îî‚îÄ‚îÄ config/
    ‚îú‚îÄ‚îÄ hdfs-site.xml              # Configuration HDFS
    ‚îî‚îÄ‚îÄ spark-defaults.conf        # Configuration Spark
```

---

## üöÄ Installation et Lancement

### Pr√©requis
- Docker >= 20.10
- Docker Compose >= 2.0
- 8GB RAM minimum
- 20GB d'espace disque

### √âtape 1: Cloner et pr√©parer l'environnement

```bash
cd bigdata-logs-analysis

# Cr√©er les r√©pertoires n√©cessaires
mkdir -p data spark/batch spark/streaming kafka config hdfs namenode datanode
```

### √âtape 2: G√©n√©rer les donn√©es de logs

```bash
# G√©n√©rer un fichier de logs d'exemple
python3 data/generate_logs.py
```

### √âtape 3: D√©marrer l'architecture

```bash
# Lancer tous les conteneurs
docker-compose up -d

# V√©rifier que tous les services sont d√©marr√©s
docker-compose ps
```

**Services disponibles:**
- Hadoop NameNode: http://localhost:9870
- Hadoop DataNode: http://localhost:9864
- Spark Master: http://localhost:8080
- Spark Worker: http://localhost:8081
- MongoDB: localhost:27017
- Kafka: localhost:9092
- Zookeeper: localhost:2181

### √âtape 4: Pr√©parer HDFS

```bash
# Acc√©der au conteneur Hadoop
docker exec -it namenode bash

# Cr√©er les r√©pertoires dans HDFS
hdfs dfs -mkdir -p /logs
hdfs dfs -mkdir -p /output

# Copier les logs dans HDFS
hdfs dfs -put /data/web_server.log /logs/

# V√©rifier
hdfs dfs -ls /logs
exit
```

---

## üîß Ex√©cution des Analyses

### Analyses Batch

#### 1. Top 10 Produits les plus consult√©s

```bash
docker exec -it spark-master bash

spark-submit \
  --master spark://spark-master:7077 \
  --packages org.mongodb.spark:mongo-spark-connector_2.12:3.0.1 \
  /spark-apps/batch/top_products.py
```

#### 2. R√©partition des Codes HTTP

```bash
spark-submit \
  --master spark://spark-master:7077 \
  --packages org.mongodb.spark:mongo-spark-connector_2.12:3.0.1 \
  /spark-apps/batch/http_codes.py
```

#### 3. Top 10 IPs les plus actives

```bash
spark-submit \
  --master spark://spark-master:7077 \
  --packages org.mongodb.spark:mongo-spark-connector_2.12:3.0.1 \
  /spark-apps/batch/top_ips.py
```

### Analyses Streaming

#### 1. D√©tection d'erreurs en temps r√©el

```bash
# Terminal 1: D√©marrer le consumer Spark Streaming
spark-submit \
  --master spark://spark-master:7077 \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0,org.mongodb.spark:mongo-spark-connector_2.12:3.0.1 \
  /spark-apps/streaming/error_detection.py
```

```bash
# Terminal 2: D√©marrer le producer Kafka
docker exec -it kafka bash
python3 /kafka-apps/log_producer.py
```

#### 2. Produits en tendance

```bash
spark-submit \
  --master spark://spark-master:7077 \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0,org.mongodb.spark:mongo-spark-connector_2.12:3.0.1 \
  /spark-apps/streaming/trending_products.py
```

---

## üìä Consultation des R√©sultats

### Via MongoDB

```bash
# Acc√©der √† MongoDB
docker exec -it mongodb mongo

# Utiliser la base de donn√©es
use logs_analytics

# Voir les collections
show collections

# Top produits
db.top_products.find().pretty()

# Codes HTTP
db.http_codes.find().pretty()

# Top IPs
db.top_ips.find().pretty()

# Alertes erreurs (streaming)
db.error_alerts.find().pretty()

# Produits tendance (streaming)
db.trending_products.find().pretty()
```

### Via HDFS (r√©sultats interm√©diaires)

```bash
# Lister les r√©sultats
docker exec -it namenode hdfs dfs -ls /output

# Voir le contenu
docker exec -it namenode hdfs dfs -cat /output/top_products/part-*
```

---

## üß™ Tests et Validation

### V√©rifier la sant√© des services

```bash
# V√©rifier HDFS
docker exec namenode hdfs dfsadmin -report

# V√©rifier Spark
curl http://localhost:8080

# V√©rifier Kafka topics
docker exec kafka kafka-topics.sh --list --bootstrap-server localhost:9092

# V√©rifier MongoDB
docker exec mongodb mongo --eval "db.adminCommand('ping')"
```

### Monitoring des logs

```bash
# Logs Spark Master
docker logs -f spark-master

# Logs Kafka
docker logs -f kafka

# Logs HDFS
docker logs -f namenode
```

---

## üõ†Ô∏è Justifications Techniques

### Pourquoi HDFS ?
- **Tol√©rance aux pannes**: R√©plication des blocs (facteur 3 par d√©faut)
- **Scalabilit√©**: Ajout facile de DataNodes
- **Performance**: Optimis√© pour gros fichiers s√©quentiels
- **Int√©gration**: Native avec Spark

### Pourquoi Spark ?
- **Performance**: Traitement in-memory (100x plus rapide que MapReduce)
- **Unification**: M√™me API pour batch et streaming
- **√âcosyst√®me**: MLlib, GraphX, Spark SQL
- **Langage**: Python (PySpark) facile √† maintenir

### Pourquoi Kafka ?
- **D√©bit**: Millions de messages/seconde
- **Persistance**: Logs durables et rejouables
- **D√©couplage**: Producteurs/consommateurs ind√©pendants
- **Scalabilit√©**: Partitionnement distribu√©

### Pourquoi MongoDB ?
- **Flexibilit√©**: Sch√©ma JSON dynamique
- **Performance**: Index optimis√©s pour requ√™tes
- **Agr√©gation**: Pipeline puissant pour analytics
- **Scalabilit√©**: Sharding horizontal

### Pourquoi Docker ?
- **Reproductibilit√©**: M√™me environnement partout
- **Isolation**: Pas de conflits de d√©pendances
- **Rapidit√©**: D√©ploiement en quelques minutes
- **Portabilit√©**: Fonctionne sur tout OS

---

## üìà Am√©liorations Possibles

1. **Visualisation**: Ajouter Grafana/Kibana pour dashboards
2. **Orchestration**: Utiliser Airflow pour pipelines complexes
3. **ML**: Pr√©diction de charge avec Spark MLlib
4. **S√©curit√©**: Authentification Kerberos, TLS
5. **Monitoring**: Prometheus + Alertmanager
6. **Stockage**: Ajouter HBase pour requ√™tes temps r√©el

---

## üêõ Troubleshooting

### Erreur: "Cannot connect to Spark Master"
```bash
docker-compose restart spark-master
docker-compose logs spark-master
```

### Erreur: "HDFS in Safe Mode"
```bash
docker exec namenode hdfs dfsadmin -safemode leave
```

### Erreur: "Kafka connection refused"
```bash
# V√©rifier Zookeeper
docker-compose restart zookeeper
# Red√©marrer Kafka
docker-compose restart kafka
```

### M√©moire insuffisante
```bash
# Augmenter la m√©moire dans docker-compose.yml
SPARK_WORKER_MEMORY=4g
```

---

## üë®‚Äçüíª Auteur

Projet r√©alis√© dans le cadre du cours de Big Data et Data Engineering.

## üìù Licence

MIT License - Usage acad√©mique et √©ducatif.
