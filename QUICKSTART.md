# âš¡ Guide de DÃ©marrage Rapide

Ce guide vous permet de lancer le projet en **moins de 10 minutes**.

---

## ğŸ“‹ PrÃ©requis

VÃ©rifiez que vous avez:
- âœ… Docker >= 20.10
- âœ… Docker Compose >= 2.0
- âœ… 8GB RAM disponible
- âœ… 20GB espace disque
- âœ… Python 3.7+

---

## ğŸš€ Installation en 5 Ã‰tapes

### Ã‰tape 1: Configuration initiale (2 min)

```bash
cd bigdata-logs-analysis
chmod +x scripts/*.sh
./scripts/setup.sh
```

**Ce script va:**
- âœ“ VÃ©rifier Docker et Docker Compose
- âœ“ CrÃ©er les rÃ©pertoires nÃ©cessaires
- âœ“ GÃ©nÃ©rer 10,000 lignes de logs d'exemple

---

### Ã‰tape 2: DÃ©marrage des services (3 min)

```bash
docker-compose up -d
```

**Attendre que tous les services dÃ©marrent (~2 minutes):**

```bash
# VÃ©rifier l'Ã©tat
docker-compose ps
```

**Vous devriez voir 7 conteneurs actifs:**
- âœ“ namenode (HDFS)
- âœ“ datanode (HDFS)
- âœ“ spark-master
- âœ“ spark-worker
- âœ“ zookeeper
- âœ“ kafka
- âœ“ mongodb

---

### Ã‰tape 3: PrÃ©paration HDFS (1 min)

```bash
./scripts/prepare_hdfs.sh
```

**Ce script va:**
- âœ“ CrÃ©er les rÃ©pertoires HDFS
- âœ“ Uploader les logs dans HDFS
- âœ“ VÃ©rifier l'upload

**Interface Web HDFS:** http://localhost:9870

---

### Ã‰tape 4: Lancer les analyses batch (2 min)

```bash
./scripts/run_batch.sh
```

**Ce script lance sÃ©quentiellement:**
1. âœ“ Top 10 Produits (~30s)
2. âœ“ RÃ©partition des Codes HTTP (~30s)
3. âœ“ Top 10 IPs Actives (~30s)

**Interface Web Spark:** http://localhost:8080

---

### Ã‰tape 5: Consulter les rÃ©sultats (1 min)

```bash
docker exec -it mongodb mongo

# Dans le shell MongoDB:
use logs_analytics
show collections

# Voir les rÃ©sultats
db.top_products.find().pretty()
db.http_codes_detailed.find().pretty()
db.top_ips.find().pretty()
```

---

## ğŸ‰ FÃ©licitations !

Vous avez maintenant une architecture Big Data distribuÃ©e fonctionnelle !

---

## ğŸ“Š Interfaces Web Disponibles

| Service | URL | Description |
|---------|-----|-------------|
| HDFS NameNode | http://localhost:9870 | Browse HDFS files |
| HDFS DataNode | http://localhost:9864 | DataNode status |
| Spark Master | http://localhost:8080 | Cluster overview |
| Spark Worker | http://localhost:8081 | Worker status |

---

## âš¡ Tester le Streaming (Optionnel)

### Terminal 1: DÃ©marrer le producteur Kafka

```bash
docker exec -it kafka bash
cd /kafka-apps
python3 log_producer.py

# Dans le menu:
# 1. Choisir "2" pour mode ERRORS (pic d'erreurs)
# 2. DurÃ©e: 300 secondes (5 minutes)
```

### Terminal 2: DÃ©marrer la dÃ©tection d'erreurs

```bash
docker exec -it spark-master bash

spark-submit \
  --master spark://spark-master:7077 \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0,org.mongodb.spark:mongo-spark-connector_2.12:3.0.1 \
  /spark-apps/streaming/error_detection.py
```

### Terminal 3: Voir les alertes en temps rÃ©el

```bash
docker exec -it mongodb mongo

use logs_analytics
# RafraÃ®chir toutes les 5 secondes
while true; do
  db.error_alerts.find().sort({detected_at: -1}).limit(5).pretty()
  sleep 5
done
```

---

## ğŸ›‘ ArrÃªter les Services

```bash
# ArrÃªt propre
./scripts/stop.sh

# OU directement
docker-compose down
```

---

## ğŸ§¹ Nettoyage Complet

**âš ï¸ ATTENTION: Supprime toutes les donnÃ©es !**

```bash
./scripts/clean.sh
```

---

## ğŸ› DÃ©pannage Rapide

### Erreur: "Cannot connect to Docker daemon"
```bash
# DÃ©marrer Docker Desktop (Mac/Windows)
# OU sur Linux:
sudo systemctl start docker
```

### Erreur: "Port already in use"
```bash
# Trouver le processus utilisant le port (exemple: 9870)
lsof -i :9870
kill -9 <PID>

# OU changer les ports dans docker-compose.yml
```

### Erreur: "HDFS in safe mode"
```bash
docker exec namenode hdfs dfsadmin -safemode leave
```

### Spark job Ã©choue avec OutOfMemory
```bash
# Augmenter la mÃ©moire dans docker-compose.yml
SPARK_WORKER_MEMORY=4G  # au lieu de 2G
docker-compose restart spark-worker
```

---

## ğŸ“š Aller Plus Loin

- **Architecture dÃ©taillÃ©e**: Voir [ARCHITECTURE.md](ARCHITECTURE.md)
- **Documentation complÃ¨te**: Voir [README.md](README.md)
- **Justifications techniques**: Voir section "MÃ©thode de Raisonnement" dans ARCHITECTURE.md

---

## ğŸ’¡ Commandes Utiles

### Logs des conteneurs
```bash
docker logs -f spark-master     # Logs Spark
docker logs -f kafka            # Logs Kafka
docker logs -f namenode         # Logs HDFS
```

### Ã‰tat du cluster
```bash
docker-compose ps               # Ã‰tat des conteneurs
docker stats                    # Usage CPU/RAM
docker exec namenode hdfs dfsadmin -report  # Ã‰tat HDFS
```

### Shell interactif
```bash
docker exec -it spark-master bash   # Shell Spark
docker exec -it namenode bash       # Shell Hadoop
docker exec -it mongodb mongo       # Shell MongoDB
```

---

## âœ… Checklist de Validation

Avant de rendre le projet, vÃ©rifiez:

- [ ] Tous les conteneurs sont en Ã©tat "Up"
- [ ] Les 3 analyses batch s'exÃ©cutent sans erreur
- [ ] Les rÃ©sultats sont visibles dans MongoDB
- [ ] HDFS contient le fichier de logs
- [ ] Les interfaces web sont accessibles
- [ ] Le streaming fonctionne (optionnel)

---

## ğŸ“ Objectifs PÃ©dagogiques Atteints

En complÃ©tant ce quickstart, vous avez:

âœ… DÃ©ployÃ© une architecture distribuÃ©e avec Docker  
âœ… ConfigurÃ© HDFS pour le stockage distribuÃ©  
âœ… ExÃ©cutÃ© des jobs Spark Batch  
âœ… TestÃ© Spark Structured Streaming (optionnel)  
âœ… IntÃ©grÃ© MongoDB pour les rÃ©sultats  
âœ… Compris le flux de donnÃ©es batch et streaming  

---

**Temps total: 10 minutes â±ï¸**

Bon courage ! ğŸš€
